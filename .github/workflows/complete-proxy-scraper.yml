name: Complete Proxy Scraper - With Test Mode

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      proxy_types:
        description: 'Proxy types to scrape'
        required: true
        default: 'all'
        type: choice
        options: [all, http, socks4, socks5]
      test_mode:
        description: 'Enable test mode (3 sources only)'
        required: false
        default: false
        type: boolean

jobs:
  scrape-proxies:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    concurrency:
      group: proxy-scraper
      cancel-in-progress: false

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install uvloop || echo "uvloop not available"

    - name: Run proxy scraper
      run: |
        PROXY_TYPE="${{ github.event.inputs.proxy_types || 'all' }}"
        TEST_MODE="${{ github.event.inputs.test_mode || 'false' }}"

        if [ "$TEST_MODE" = "true" ]; then
          echo "ðŸ§ª Running in TEST MODE"
          timeout 1800 python complete_proxy_scraper.py --proxy-type "$PROXY_TYPE" --test-mode
        else
          echo "ðŸš€ Running in PRODUCTION MODE" 
          timeout 5400 python complete_proxy_scraper.py --proxy-type "$PROXY_TYPE"
        fi
      timeout-minutes: 85

    # ... rest of your existing workflow steps ...
